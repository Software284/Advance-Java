Transaction Management In JDBC:->
-> Process of combining all related operations into a single unit and executing on the rule
"either all or none" is called transation management.
-> hence transaction is a single unit of work and it will work on the rule "either all or none"

Case-1:Funds Transfer
1. debit funds from senders account
2. credit funds into receivers account


-> All operations should be performed as a single unit only. if debit from senders account
completed and credit into receivers account fails then there may be a chance of data inconsistency
problems.

Case-2: Movie Ticket Reservation
1.Verifyy the status
2.Reserve the tickets
3. Payment
4.issue tickets.

All operations should be performed as a single unit only. if some operations success and
some operations fails then there may be data inconsistency problems.


Types of Transactions:
-> There are two types of transations
i. Local Transactions
ii. Global Transactions

Local Transations:->
-> All operations in a transaction are execute over same database
-> Eg: Funds transfer from one account to another account where both accounts in the same bank

Global Transactions:->
-> All operations is a transaction are expected over different databases.
-> Eg: Funds Transfer from one account to another account and accounts are related to different
banks.

Note:-> JDBC can provide support only for local transactions. if we want global transaction
then we have to go for EJB or Spring framework.

Process of Transaction Management in JDBC:->

i. Disable auto commit mode of JDBC:->
-> By default auto commit mode is enabled. i.e after executing every sql query,the changes
will be committed automatically in the database.
we can disable auto commit mode as follows
con.setAutoCommit(false);

ii. If all operations completed then we can commit the transaction by using the following
method.
con.commit();

iii. if any sql query fails then we have to rollback operations which are already completed by
using rollback() method.
con.rollback();

Savepoint(I):->
-> Introduced in JDBC 3.0 version.
-> Driver Software Vendor is responsible to provide implementation.
-> Savepoint concept is applicable only in transactions.
->Within a transaction if we want to rollback a particular group of operations based on 
some condition then we should go for Savepoint.
-> We can set Savepoint by using setSavepoint() method of Connection interface.
Savepoint sp = con.setSavepoint();
-> To perform rollback operation for a particular group of operations with respect to Savepoint,
we can use rollback() method as follows.
con.rollback(sp);
-> we can release or delete Savepoint by using release Savepoint() method of Connection
interface.

Case Study:->
con.setAutoCommit(false);
Operation-1;
Operation-2;
Operation-3;
Savepoint sp = con.setSavepoint();
Operation-4;
Operation-5;
if(balance <10000){
con.rollback(sp);
}
else{
con.releaseSavepoint(sp);
}
Operation-6;
con.commit();

-> At line-1 if balance<10000 then operations 4 and 5 will be Rollback,otherwise all 
operations will be performed normally.

Transaction Concurrency Problem:->

i. Dirty Read Problem:->
-> Also known as uncommitted dependency problem.
-> Before commiting the transaction, if its intermediate results used by any other transaction
then there may be a chance of data inconsistency problems. This is called dirty read 
problem.
Durga:50000
T1:->update accounts set balance=balance+50000 where name='durga'
T2:-> select balance from accounts where name='durga'
T1:->con.rollback();
-> at the end, T1 point of view,durga has 50000 balance and T2 point of view durga has
1 lakh. There may be a chance of data inconsistency problem. This is called dirty read 
problem.

ii. Non-Repeatable Read Problem
-> For the same Read Operation, in the same transaction if we get different results at 
different times,then such type of problem is called Non-repeatable Read Problem.
Eg:
T1: select * from employees;
T2: update employees set esal=10000 where ename='durga';
T1: select * from employees;

-> in the above example Transaction-1 got different results at different times for the same
query.


iii. Phantom Read Problem
-> A phantom read occurs when one transaction reads all the rows that satisfy a where 
condition and second transaction insert a new row that satisfy same where condition. if
the first transaction reads for the same condition in the result an additional row will
come. this row is called phantom row and this problem is called phantom read problem

T1: select * from employees where esal > 5000;
T2: insert into employees values(300,'ravi',8000,'hyd');
T1: select * from employees where esal > 5000;

-> In the above code whenever transaction-1 performing read operation second time, a new
row will come in the result.
-> To overcome these problems we shourld go for Transaction isolation levels
-> Connection interface defines the following 4 transaction isolation levels.
i.TRANSACTION_NONE -> 0
ii. TRANSACTION_READ_UNCOMMITTED -> 1
iii. TRANSACTION_READ_COMMITTED -> 2
iv. TRANSACTION_REPEATABLE_READ -> 4
v. TRANSACTION_SERIALIZABLE -> 8


Transaction Read Uncommitted:->
-> it is the lowest level of isolation.
-> Before committing the transaction its intermediate results can be used by other transactions.
-> internally it won't use any locks
-> it does not prevent dirty read problem,non-repeatable read problem and phantom read 
problem.
-> we can use this isolation level just to indicate database supports transactions.
-> this isolation level is not recommended to use.

Transaction Read Committed:->
-> This isolation level ensures that only committed data can be read by other transactions.
-> it prevents Dirty Read Problem. But there may be a chance of Non Repeatable Read Problem
and Phantom Read Problem

Transaction Repeatable Read:->
-> This is the default value for most of the database. Internally the result of SQL Query
will be locked for only one transaction. if we perform multiple read operations,then there is
a gurantee that for same result.
-> it prevents dirty read problem and non repeatable read problems. but still there may be
a chance of phantom read problem.


Transaction Serializable:->
-> it is the highest level of isolation.
-> The total table will be locked for one transaction at a time.
-> it prevents dirty read,non-repeatable read and phantom read problems.
-> Not recommended to use because it may creates performance problems.
-> connection interface defines the following method to know isolation level.
getTransactionIsolation();
-> connection interface defines the following method to set our own isolation level.
setTransactionIsolation(int level);

Oracle Supported Isolation Level-> 2,8 where 2 is default
Mysql Supported Isolation Level -> 1,2,4,8







